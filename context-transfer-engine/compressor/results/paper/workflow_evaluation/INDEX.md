# Workflow Evaluation - Complete Index

## Overview

This evaluation compares different archival strategies for a Gray-Scott simulation workflow (Produce â†’ Consume â†’ Archive).

**Configuration**: 192 ranks (8 nodes Ã— 24 ranks/node), 2MB per rank = 384MB total per iteration

**Key Finding**: Offloading compression to the consumer is **highly worthwhile**, achieving **38.7Ã— speedup** over local compression (HCompress) and **56.8Ã— speedup** over PFS-based archival.

---

## Files Generated

### ðŸ“Š Figures and Visualizations

1. **`workflow_time_breakdown.pdf`** / **`.svg`**
   - Stacked bar chart showing time breakdown (simulation, compression, I/O)
   - Shows DTSchedule has **empty compression bars** (offloaded to consumer)
   - Clearly demonstrates where time is spent in each strategy

2. **`workflow_speedup_comparison.pdf`** / **`.svg`**
   - Horizontal bar chart comparing speedup vs. PFS-Lossless baseline
   - DTSchedule achieves **>50Ã— speedup**
   - Visual proof of offloading effectiveness

3. **`pipeline_efficiency.pdf`** / **`.svg`**
   - Pipeline diagram comparing HCompress (sequential) vs. DTSchedule (pipelined)
   - Shows how DTSchedule overlaps consumer compression with producer simulation
   - Demonstrates pipelining advantage

### ðŸ“„ Data and Results

4. **`workflow_evaluation_results.csv`**
   - Complete numerical results for all scenarios
   - Columns: scenario, data_size_mb, compressed_size_mb, compress_time_ms, io_time_ms, sim_time_ms, consumer_compress_time_ms, total_time_ms, compression_ratio, offload_compression
   - Machine-readable format for further analysis

5. **`offload_analysis.json`**
   - JSON summary of offload worthiness analysis
   - Speedup: 38.71Ã—, Time saved: 40,604 ms, Worthwhile: true

6. **`EVALUATION_SUMMARY.txt`**
   - Human-readable text summary
   - Configuration, results table, and offload analysis

### ðŸ“ Documentation

7. **`README.md`**
   - Comprehensive documentation of the evaluation
   - Explains configuration, scenarios, findings, and methodology
   - Includes reproduction instructions

8. **`ANSWERS_TO_QUESTIONS.md`**
   - Direct answers to your two questions:
     1. Is offloading compression worthwhile? **YES, 38.7Ã— speedup**
     2. Breakdown figures? **Generated (see above)**
   - Quantitative evidence and break-even analysis

9. **`PAPER_WORKFLOW_TABLE.tex`**
   - LaTeX table ready for inclusion in paper
   - Professional formatting with booktabs
   - Two versions: compact and detailed (with consumer compression times)
   - Includes explanatory footnotes

10. **`INDEX.md`** (this file)
    - Overview and index of all generated materials

### ðŸ”§ Scripts

11. **`generate_workflow_evaluation.py`**
    - Main evaluation script
    - Calculates time breakdown for all scenarios
    - Generates figures and CSV results
    - Performs offload worthiness analysis

12. **`generate_pipeline_diagram.py`**
    - Pipeline efficiency visualization script
    - Shows sequential vs. pipelined execution

---

## Quick Reference

### Key Numbers

| Scenario | Total Time (ms) | Speedup vs. Baseline |
|----------|-----------------|----------------------|
| PFS-Lossless (Baseline) | 61,208 | 1.00Ã— |
| PFS-FPZip-Best | 3,454 | 17.72Ã— |
| HCompress | 41,681 | 1.47Ã— |
| **DTSchedule-Lossless** | **1,077** | **56.84Ã—** |
| DTSchedule-Lossy-500dB | 1,077 | 56.84Ã— |
| DTSchedule-Lossy-150dB | 1,077 | 56.84Ã— |

### Answer to Question 1: Is Offloading Worthwhile?

**YES!** DTSchedule achieves **38.7Ã— speedup** over HCompress by offloading compression.

**Why?**
- Network transfer (77 ms) is **525Ã— faster** than compression (40,320 ms)
- Eliminates I/O interference (saves 150 ms simulation time)
- Enables pipelining (consumer compresses while producer simulates)

### Answer to Question 2: Figures Generated?

**YES!** Three sets of figures generated:

1. **Time Breakdown**: Shows simulation/compression/I/O breakdown
   - DTSchedule has **empty compression bars** (offloaded)

2. **Speedup Comparison**: Shows relative performance
   - DTSchedule achieves **>50Ã— speedup**

3. **Pipeline Efficiency**: Shows pipelining advantage
   - DTSchedule overlaps operations for efficiency

---

## Usage

### For Paper

Include the LaTeX table:
```latex
\input{workflow_evaluation/PAPER_WORKFLOW_TABLE.tex}
```

Include figures:
```latex
\begin{figure}
  \includegraphics[width=\columnwidth]{workflow_evaluation/workflow_time_breakdown.pdf}
  \caption{Workflow time breakdown...}
\end{figure}
```

### For Presentation

Use the generated PDF/SVG figures directly in slides.

### For Further Analysis

Load the CSV data:
```python
import pandas as pd
df = pd.read_csv('workflow_evaluation_results.csv')
```

### Regenerate All Results

```bash
cd /workspace/context-transport-primitives/test/unit/compress/results/paper/workflow_evaluation
python3 generate_workflow_evaluation.py
python3 generate_pipeline_diagram.py
```

---

## Configuration Details

### System Setup
- **Ranks**: 192 (8 nodes Ã— 24 ranks/node)
- **Data per rank**: 2 MB
- **Total data**: 384 MB per iteration
- **Simulation baseline**: 1,000 ms
- **I/O interference**: 15% slowdown

### Bandwidth
- **PFS**: 500 MB/s total (62.5 MB/s per node)
- **NVMe**: 1 GB/s
- **DRAM**: 10 GB/s
- **Network**: 40 Gbps = 5 GB/s

### Compression
- **Lossless**: 40% CR, 150 ms/MB
- **Lossy Fast**: 25% CR, 2 ms/MB
- **Lossy Medium**: 10% CR, 2 ms/MB
- **Lossy High**: 3% CR, 2 ms/MB

---

## Scenarios Evaluated

1. **PFS-Lossless**: Baseline (compress + write to PFS during production)
2. **PFS-FPZip-Best**: Fast lossy + write to PFS during production
3. **HCompress**: Compress + write to local NVMe during production
4. **DTSchedule-Lossless**: Offload lossless compression to consumer
5. **DTSchedule-Lossy-500dB**: Offload lossy compression to consumer
6. **DTSchedule-Lossy-150dB**: Offload high lossy compression to consumer

---

## Key Insights

1. **Offloading is highly worthwhile**: 38.7Ã— speedup over HCompress
2. **Network bandwidth is key**: 5 GB/s >> compression speed
3. **Pipelining provides efficiency**: Consumer compresses while producer simulates next iteration
4. **Flexibility in quality**: Same producer performance across compression ratios
5. **PFS is a bottleneck**: Slow bandwidth and high overhead

---

## Contact

For questions or issues with this evaluation, please refer to:
- `README.md` for detailed methodology
- `ANSWERS_TO_QUESTIONS.md` for direct Q&A
- `EVALUATION_SUMMARY.txt` for text summary

Generated: 2026-01-30
