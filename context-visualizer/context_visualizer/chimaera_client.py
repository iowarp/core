"""Wrapper around chimaera_runtime_ext for the visualizer."""

import concurrent.futures
import socket
import threading

try:
    import msgpack
except ImportError:
    msgpack = None

# Default timeout (seconds) for async_monitor calls.  Broadcasts that include
# dead nodes can block for 30+ seconds waiting on retries, so we cap them.
_MONITOR_TIMEOUT = 10

_lock = threading.Lock()
_chi = None
_init_done = False


def _ensure_init():
    """Lazy-initialize the Chimaera client connection."""
    global _chi, _init_done
    if _init_done:
        return
    with _lock:
        if _init_done:
            return
        import chimaera_runtime_ext as chi
        _chi = chi
        # 0 = kClient — pass a plain int to avoid any nanobind enum objects
        ok = chi.chimaera_init(0)
        if not ok:
            raise RuntimeError("chimaera_init(kClient) failed -- is the runtime running?")
        _init_done = True


def _decode_results(results):
    """Decode a {container_id: bytes} dict into {container_id: decoded_data}."""
    decoded = {}
    for cid, blob in results.items():
        if msgpack is not None and isinstance(blob, (bytes, bytearray)):
            try:
                decoded[str(cid)] = msgpack.unpackb(blob, raw=False)
            except Exception:
                decoded[str(cid)] = blob
        else:
            decoded[str(cid)] = blob
    return decoded


def _do_monitor(pool_query, query):
    """Run async_monitor + wait in the calling thread (used by _monitor)."""
    return _chi.async_monitor(pool_query, query).wait()


def _monitor(pool_query, query, timeout=_MONITOR_TIMEOUT):
    """Execute an async_monitor call with a timeout.

    Both async_monitor() and .wait() can block when the runtime or a
    target node is dead, so the entire operation runs in a worker thread
    with shutdown(wait=False) to avoid blocking the caller.
    """
    _ensure_init()
    pool = concurrent.futures.ThreadPoolExecutor(max_workers=1)
    future = pool.submit(_do_monitor, pool_query, query)
    try:
        results = future.result(timeout=timeout)
    except concurrent.futures.TimeoutError:
        pool.shutdown(wait=False)
        raise TimeoutError(
            f"Monitor({pool_query!r}, {query!r}) timed out after {timeout}s"
        )
    pool.shutdown(wait=False)
    return _decode_results(results)


def is_connected():
    """Return True if the client has been initialized."""
    return _init_done


def get_worker_stats():
    """Query worker_stats from the admin pool (local node)."""
    return _monitor("local", "worker_stats")


def get_pool_worker_stats(pool_id_str, routing="local"):
    """Query worker_stats for a specific pool via pool_stats:// URI."""
    return _monitor("local", f"pool_stats://{pool_id_str}:{routing}:worker_stats")


def get_status():
    """Query general status from the admin pool."""
    return _monitor("local", "status")


def get_system_stats(pool_query="local", min_event_id=0):
    """Query system_stats from the admin pool."""
    return _monitor(pool_query, f"system_stats:{min_event_id}")


def get_system_stats_all(min_event_id=0):
    """Broadcast system_stats to all nodes (each self-identifies via hostname/ip/node_id)."""
    return _monitor("broadcast", f"system_stats:{min_event_id}")


def check_nodes_alive(ip_list, port=9413, timeout=1):
    """Check which nodes are alive by attempting a TCP connection to their RPC port.

    Returns a set of indices (matching ip_list positions) that are alive.
    This avoids the C++ runtime's IPC layer which blocks on dead nodes.
    """
    alive = set()

    def _check_one(idx, ip):
        try:
            s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
            s.settimeout(timeout)
            s.connect((ip, port))
            s.close()
            return idx
        except Exception:
            return None

    with concurrent.futures.ThreadPoolExecutor(max_workers=max(len(ip_list), 1)) as pool:
        futures = [pool.submit(_check_one, i, ip) for i, ip in enumerate(ip_list)]
        for f in concurrent.futures.as_completed(futures, timeout=timeout + 2):
            try:
                idx = f.result()
                if idx is not None:
                    alive.add(idx)
            except Exception:
                pass

    return alive


def get_system_stats_per_node(node_ids, min_event_id=0, timeout=3):
    """Query system_stats for each node individually in parallel.

    Returns {node_id: entry_dict} for nodes that responded, skipping
    dead nodes instead of blocking the whole request.
    """
    _ensure_init()
    results = {}

    def _query_one(node_id):
        try:
            raw = _monitor(f"physical:{node_id}", f"system_stats:{min_event_id}", timeout=timeout)
            # Use the last (most recent) entry from the ring buffer
            latest = None
            for cid, entries in raw.items():
                if isinstance(entries, list):
                    for entry in entries:
                        if isinstance(entry, dict):
                            latest = entry
            if latest is not None:
                return (node_id, latest)
        except Exception:
            pass
        return (node_id, None)

    with concurrent.futures.ThreadPoolExecutor(max_workers=len(node_ids)) as pool:
        futures = [pool.submit(_query_one, nid) for nid in node_ids]
        for f in concurrent.futures.as_completed(futures, timeout=timeout + 2):
            try:
                nid, entry = f.result()
                if entry is not None:
                    results[nid] = entry
            except Exception:
                pass

    return results


def get_bdev_stats(pool_query="local"):
    """Query bdev_stats from the admin pool."""
    return _monitor(pool_query, "bdev_stats")


def get_worker_stats_for_node(node_id):
    """Query worker_stats for a specific node."""
    return _monitor(f"physical:{node_id}", "worker_stats")


def get_system_stats_for_node(node_id, min_event_id=0):
    """Query system_stats for a specific node."""
    return _monitor(f"physical:{node_id}", f"system_stats:{min_event_id}")


def get_bdev_stats_for_node(node_id):
    """Query bdev_stats for a specific node."""
    return _monitor(f"physical:{node_id}", "bdev_stats")


def get_host_info(node_id):
    """Query host info (hostname, ip_address, node_id) for a specific node."""
    decoded = _monitor(f"physical:{node_id}", "get_host_info")
    for entry in decoded.values():
        if isinstance(entry, dict):
            return entry
    return {}


def shutdown_node(ip_address, grace_period_ms=5000):
    """Shutdown a remote node via SSH.

    First attempts graceful shutdown with 'chimaera runtime stop'.
    Exit codes 0, 134 (SIGABRT), and 255 (SSH closed) are success.
    If graceful stop fails, forcefully kills the runtime process.
    """
    import subprocess

    # Step 1: Try graceful shutdown
    cmd = [
        "ssh",
        "-o", "StrictHostKeyChecking=no",
        "-o", "ConnectTimeout=5",
        ip_address,
        f"export PATH=/workspace/build/bin:$PATH LD_LIBRARY_PATH=/workspace/build/bin:$LD_LIBRARY_PATH && chimaera runtime stop --grace-period {grace_period_ms}",
    ]
    try:
        result = subprocess.run(cmd, capture_output=True, text=True, timeout=15)
        if result.returncode in (0, 134, 255):
            return {
                "success": True,
                "returncode": result.returncode,
                "stdout": result.stdout,
                "stderr": result.stderr,
            }
    except subprocess.TimeoutExpired:
        pass

    # Step 2: Graceful stop failed or timed out — force kill
    kill_cmd = [
        "ssh",
        "-o", "StrictHostKeyChecking=no",
        "-o", "ConnectTimeout=5",
        ip_address,
        "pkill -9 -f 'chimaera runtime start' 2>/dev/null; sleep 0.5; "
        "! pgrep -f 'chimaera runtime start' >/dev/null 2>&1",
    ]
    try:
        kill_result = subprocess.run(
            kill_cmd, capture_output=True, text=True, timeout=10)
        # pgrep exits 1 when no processes found (good — runtime is dead)
        return {
            "success": True,
            "returncode": kill_result.returncode,
            "stdout": "Force-killed runtime process",
            "stderr": "",
        }
    except Exception as exc:
        return {
            "success": False,
            "returncode": -1,
            "stdout": "",
            "stderr": f"Both graceful and forced shutdown failed: {exc}",
        }


def restart_node(ip_address, port=9413, wait_timeout=10):
    """Restart a remote node via SSH.

    1. Kills any existing runtime process (force kill to avoid hangs).
    2. Forwards runtime environment variables (CHI_SERVER_CONF, etc.).
    3. Starts the runtime in the background via nohup + setsid.
    4. Polls the node's TCP port to verify the runtime came up.

    Returns success only when the node is actually accepting connections.
    """
    import os
    import time
    import subprocess

    # Step 1: Kill any existing runtime process to free the port.
    # Uses SIGKILL to avoid the graceful stop hanging for 30s.
    kill_cmd = [
        "ssh",
        "-o", "StrictHostKeyChecking=no",
        "-o", "ConnectTimeout=5",
        ip_address,
        "pkill -9 -f 'chimaera runtime start' 2>/dev/null; sleep 1",
    ]
    try:
        subprocess.run(kill_cmd, capture_output=True, text=True, timeout=10)
    except Exception:
        pass  # OK if nothing to kill

    # Step 2: Build the environment and start the runtime.
    env_parts = [
        "export PATH=/workspace/build/bin:$PATH",
        "LD_LIBRARY_PATH=/workspace/build/bin:$LD_LIBRARY_PATH",
    ]
    for var in ("CHI_SERVER_CONF", "CHI_NUM_CONTAINERS",
                "CONTAINER_HOSTFILE"):
        val = os.environ.get(var)
        if val:
            env_parts.append(f"{var}={val}")
    env_str = " ".join(env_parts)
    log_file = "/tmp/chimaera_restart.log"
    # setsid creates a new session so the process is fully detached from SSH.
    # nohup prevents SIGHUP when SSH disconnects.
    remote_cmd = (
        f"{env_str} && "
        f"nohup setsid /workspace/build/bin/chimaera runtime start "
        f"</dev/null >{log_file} 2>&1 &"
    )
    cmd = [
        "ssh",
        "-o", "StrictHostKeyChecking=no",
        "-o", "ConnectTimeout=5",
        ip_address,
        remote_cmd,
    ]
    result = subprocess.run(cmd, capture_output=True, text=True, timeout=15)
    if result.returncode != 0:
        return {
            "success": False,
            "returncode": result.returncode,
            "stdout": result.stdout,
            "stderr": result.stderr,
        }

    # Step 3: Poll the node's main port to verify the runtime started.
    deadline = time.monotonic() + wait_timeout
    while time.monotonic() < deadline:
        try:
            s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
            s.settimeout(1)
            s.connect((ip_address, port))
            s.close()
            return {
                "success": True,
                "returncode": 0,
                "stdout": "Runtime is accepting connections",
                "stderr": "",
            }
        except Exception:
            pass
        time.sleep(1)

    # Node didn't come up — fetch the log file for diagnostics.
    log_output = ""
    try:
        log_cmd = [
            "ssh", "-o", "StrictHostKeyChecking=no",
            "-o", "ConnectTimeout=5",
            ip_address,
            f"tail -30 {log_file} 2>/dev/null",
        ]
        log_result = subprocess.run(
            log_cmd, capture_output=True, text=True, timeout=10)
        log_output = log_result.stdout
    except Exception:
        pass

    return {
        "success": False,
        "returncode": -1,
        "stdout": "",
        "stderr": f"Runtime did not start within {wait_timeout}s. "
                  f"Log from {log_file}:\n{log_output}",
    }


def finalize():
    """Clean shutdown of the Chimaera client."""
    global _init_done
    if _init_done and _chi is not None:
        _chi.chimaera_finalize()
        _init_done = False
